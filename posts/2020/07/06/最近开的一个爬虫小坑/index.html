<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>最近开的一个爬虫小坑 | 烂杯的博客</title><meta name=keywords content="python,selenium,requests"><meta name=description content="第一次全程使用selenium爬数据"><meta name=author content="cgcel"><link rel=canonical href=https://cgcel.github.io/posts/2020/07/06/%E6%9C%80%E8%BF%91%E5%BC%80%E7%9A%84%E4%B8%80%E4%B8%AA%E7%88%AC%E8%99%AB%E5%B0%8F%E5%9D%91/><link crossorigin=anonymous href=/assets/css/stylesheet.min.ec8da366ca2fb647537ccb7a8f6fa5b4e9cd3c7a0d3171dd2d3baad1e49c8bfc.css integrity="sha256-7I2jZsovtkdTfMt6j2+ltOnNPHoNMXHdLTuq0eSci/w=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.2840b7fccd34145847db71a290569594bdbdb00047097f75d6495d162f5d7dff.js integrity="sha256-KEC3/M00FFhH23GikFaVlL29sABHCX911kldFi9dff8=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://cgcel.github.io/images/avatar.jpg><link rel=icon type=image/png sizes=16x16 href=https://cgcel.github.io/images/avatar.jpg><link rel=icon type=image/png sizes=32x32 href=https://cgcel.github.io/images/avatar.jpg><link rel=apple-touch-icon href=https://cgcel.github.io/images/avatar.jpg><link rel=mask-icon href=https://cgcel.github.io/images/avatar.jpg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="最近开的一个爬虫小坑"><meta property="og:description" content="第一次全程使用selenium爬数据"><meta property="og:type" content="article"><meta property="og:url" content="https://cgcel.github.io/posts/2020/07/06/%E6%9C%80%E8%BF%91%E5%BC%80%E7%9A%84%E4%B8%80%E4%B8%AA%E7%88%AC%E8%99%AB%E5%B0%8F%E5%9D%91/"><meta property="og:image" content="https://cgcel.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-07-06T21:43:54+08:00"><meta property="article:modified_time" content="2020-07-06T21:43:54+08:00"><meta property="og:site_name" content="CGCEL BLOG"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://cgcel.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="最近开的一个爬虫小坑"><meta name=twitter:description content="第一次全程使用selenium爬数据"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://cgcel.github.io/posts/"},{"@type":"ListItem","position":3,"name":"最近开的一个爬虫小坑","item":"https://cgcel.github.io/posts/2020/07/06/%E6%9C%80%E8%BF%91%E5%BC%80%E7%9A%84%E4%B8%80%E4%B8%AA%E7%88%AC%E8%99%AB%E5%B0%8F%E5%9D%91/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"最近开的一个爬虫小坑","name":"最近开的一个爬虫小坑","description":"第一次全程使用selenium爬数据","keywords":["python","selenium","requests"],"articleBody":"起因 去年年底开始, 部门里统计每月运维分队保障情况的任务就落到了我们头上, 大家都不是很愿意去做, 毕竟是重复劳动, 没有什么意义, 在信息系统里查起来还比较麻烦, 数据要一个一个地对, 然后根据当月分队的排班情况算到每个分队的统计里, 并按照规则排名以及打分, 一般都是每个月23或者24号开始统计, 正好这个月我 21-24 号放假加调休, 心想终于躲过一劫的我居然在回到公司上班的第一天被通知由我来统计! 无奈之下我只好以最快的速度做完, 但是这样下去什么时候才是个头啊, 于是就萌生了自己造轮子的想法, 正好复习一下自学的 python 爬虫.\n尝试 requests 写些小爬虫的时候, 用 requests 是最方便的. 一般来说模拟登录成功的话也就成功了一半, 后续数据可以轻松获得. 但是信息系统的一些前端渲染的数据无法通过 requests 获得, 比如下面使用 BeautifulSoup 解析后没有数据:\n1  span id=\"lblCount\" style=\"color:#C00000;font-weight:bold;\"span   selenium 于是我只能用 selenium 来写, 这也是我第一次全程用 selenium 实现功能的爬虫. selenium 的使用也非常简单, 思路就是使用 find_element_by_id() 和 find_element_by_xpath() 来操作浏览器点击或者输入信息, 将响应后的网页源码通过 BeautifulSoup 解析, 得到想要的数据, 如下:\n1  span id=\"lblCount\" style=\"color:#C00000;font-weight:bold;\"1span   处理数据 有了数据之后还要解决一个问题, 也就是推出各个分队的排班, 以便将爬到的数据算到对应责任分队处, 我是用了建 dict 和 list 的方式, 将4天一周期的分队排班和时间段结合, 得出正确的排班, 同时也新建各种dict用于存放分队运行数据, 如延误行李数, 事前维修次数, 责任分区维修次数, 值班日志以及根据这些数据排序得到的分数等等.\n运行环境   Windows 7-10\n  与本机 Chrome 版本对应的 chromedriver (项目中版本为 Chrome version 89)\n 下载链接1 下载链接2 下载链接3    Microsoft Office 或其他\n  工作原理 编译环境:  Python 3.8.6 (64-bit) Visual Studio Code  安装依赖:  selenium openpyxl bs4 pyyaml tqdm lxml  实现原理:  通过 selenium 调用 chromedriver 打开 chrome, 打开信息系统登录页面并模拟登录 登录成功后请求对应延误行李, 值班日志等页面, 使用 BeautifulSoup, re 爬取数据 对数据进行处理后, 使用 openpyxl 将数据写入 Excel 中 功能调试完成后将 chrome 设置为 headless browser, 优化使用体验  使用方法  打开 config.yaml, 按照指引修改 账号, 密码, 起始日期, 结束日期, 刷新间隔, 航站楼, 内外网访问模式, 运行模式, 其中 刷新间隔 可按需修改, 修改完保存配置 运行 main.exe 或 main.py 程序窗口将显示爬取进度, 运行完毕后, 统计结果 以及 分队排班表 以 Excel 格式保存在 \\output 目录中  后续 脚本我从 v1.0 开始记录, 在使用过程中一直有遇到新的bug, 导致统计数字有问题, 期间也是一直有维护, 修了几个bug, 直到最近更新到了 v2.6.3, 相信统计功能已经接近完美 (flag)\n不过也是多亏了同事一直有帮忙检验表格准确性, 这些 bug 才得以被修复, 如果是我自己用估计也不会发现.\n","wordCount":"183","inLanguage":"en","datePublished":"2020-07-06T21:43:54+08:00","dateModified":"2020-07-06T21:43:54+08:00","author":{"@type":"Person","name":"cgcel"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://cgcel.github.io/posts/2020/07/06/%E6%9C%80%E8%BF%91%E5%BC%80%E7%9A%84%E4%B8%80%E4%B8%AA%E7%88%AC%E8%99%AB%E5%B0%8F%E5%9D%91/"},"publisher":{"@type":"Organization","name":"烂杯的博客","logo":{"@type":"ImageObject","url":"https://cgcel.github.io/images/avatar.jpg"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://cgcel.github.io accesskey=h title="烂杯的博客 (Alt + H)"><img src=https://cgcel.github.io/images/avatar.jpg alt=logo aria-label=logo height=35>烂杯的博客</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://cgcel.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://cgcel.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://cgcel.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://cgcel.github.io>Home</a>&nbsp;»&nbsp;<a href=https://cgcel.github.io/posts/>Posts</a></div><h1 class=post-title>最近开的一个爬虫小坑</h1><div class=post-description>第一次全程使用selenium爬数据</div><div class=post-meta><span title="2020-07-06 21:43:54 +0800 CST">July 6, 2020</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;cgcel</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e8%b5%b7%e5%9b%a0 aria-label=起因>起因</a></li><li><a href=#%e5%b0%9d%e8%af%95 aria-label=尝试>尝试</a><ul><li><a href=#requests aria-label=requests>requests</a></li><li><a href=#selenium aria-label=selenium>selenium</a></li><li><a href=#%e5%a4%84%e7%90%86%e6%95%b0%e6%8d%ae aria-label=处理数据>处理数据</a></li></ul></li><li><a href=#%e8%bf%90%e8%a1%8c%e7%8e%af%e5%a2%83 aria-label=运行环境>运行环境</a></li><li><a href=#%e5%b7%a5%e4%bd%9c%e5%8e%9f%e7%90%86 aria-label=工作原理>工作原理</a><ul><li><a href=#%e7%bc%96%e8%af%91%e7%8e%af%e5%a2%83 aria-label=编译环境:>编译环境:</a></li><li><a href=#%e5%ae%89%e8%a3%85%e4%be%9d%e8%b5%96 aria-label=安装依赖:>安装依赖:</a></li><li><a href=#%e5%ae%9e%e7%8e%b0%e5%8e%9f%e7%90%86 aria-label=实现原理:>实现原理:</a></li></ul></li><li><a href=#%e4%bd%bf%e7%94%a8%e6%96%b9%e6%b3%95 aria-label=使用方法>使用方法</a></li><li><a href=#%e5%90%8e%e7%bb%ad aria-label=后续>后续</a></li></ul></div></details></div><div class=post-content><h2 id=起因>起因<a hidden class=anchor aria-hidden=true href=#起因>#</a></h2><p>去年年底开始, 部门里统计每月运维分队保障情况的任务就落到了我们头上, 大家都不是很愿意去做, 毕竟是重复劳动, 没有什么意义, 在信息系统里查起来还比较麻烦, 数据要一个一个地对, 然后根据当月分队的排班情况算到每个分队的统计里, 并按照规则排名以及打分, 一般都是每个月23或者24号开始统计, 正好这个月我 21-24 号放假加调休, 心想终于躲过一劫的我居然在回到公司上班的第一天被通知由我来统计! 无奈之下我只好以最快的速度做完, 但是这样下去什么时候才是个头啊, 于是就萌生了自己造轮子的想法, 正好复习一下自学的 python 爬虫.</p><h2 id=尝试>尝试<a hidden class=anchor aria-hidden=true href=#尝试>#</a></h2><h3 id=requests>requests<a hidden class=anchor aria-hidden=true href=#requests>#</a></h3><p>写些小爬虫的时候, 用 requests 是最方便的. 一般来说模拟登录成功的话也就成功了一半, 后续数据可以轻松获得. 但是信息系统的一些前端渲染的数据无法通过 requests 获得, 比如下面使用 BeautifulSoup 解析后没有数据:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-html data-lang=html><span class=line><span class=cl><span class=p>&lt;</span><span class=nt>span</span> <span class=na>id</span><span class=o>=</span><span class=s>&#34;lblCount&#34;</span> <span class=na>style</span><span class=o>=</span><span class=s>&#34;color:#C00000;font-weight:bold;&#34;</span><span class=p>&gt;&lt;/</span><span class=nt>span</span><span class=p>&gt;</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=selenium>selenium<a hidden class=anchor aria-hidden=true href=#selenium>#</a></h3><p>于是我只能用 selenium 来写, 这也是我第一次全程用 selenium 实现功能的爬虫. selenium 的使用也非常简单, 思路就是使用 <code>find_element_by_id()</code> 和 <code>find_element_by_xpath()</code> 来操作浏览器点击或者输入信息, 将响应后的网页源码通过 BeautifulSoup 解析, 得到想要的数据, 如下:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-html data-lang=html><span class=line><span class=cl><span class=p>&lt;</span><span class=nt>span</span> <span class=na>id</span><span class=o>=</span><span class=s>&#34;lblCount&#34;</span> <span class=na>style</span><span class=o>=</span><span class=s>&#34;color:#C00000;font-weight:bold;&#34;</span><span class=p>&gt;</span>1<span class=p>&lt;/</span><span class=nt>span</span><span class=p>&gt;</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=处理数据>处理数据<a hidden class=anchor aria-hidden=true href=#处理数据>#</a></h3><p>有了数据之后还要解决一个问题, 也就是推出各个分队的排班, 以便将爬到的数据算到对应责任分队处, 我是用了建 dict 和 list 的方式, 将4天一周期的分队排班和时间段结合, 得出正确的排班, 同时也新建各种dict用于存放分队运行数据, 如延误行李数, 事前维修次数, 责任分区维修次数, 值班日志以及根据这些数据排序得到的分数等等.</p><h2 id=运行环境>运行环境<a hidden class=anchor aria-hidden=true href=#运行环境>#</a></h2><ul><li><p>Windows 7-10</p></li><li><p>与本机 Chrome 版本对应的 <code>chromedriver</code> (项目中版本为 <code>Chrome version 89</code>)</p><ul><li><a href=https://sites.google.com/a/chromium.org/chromedriver/downloads>下载链接1</a></li><li><a href=http://chromedriver.storage.googleapis.com/index.html>下载链接2</a></li><li><a href=http://npm.taobao.org/mirrors/chromedriver>下载链接3</a></li></ul></li><li><p>Microsoft Office 或其他</p></li></ul><h2 id=工作原理>工作原理<a hidden class=anchor aria-hidden=true href=#工作原理>#</a></h2><h3 id=编译环境>编译环境:<a hidden class=anchor aria-hidden=true href=#编译环境>#</a></h3><ul><li>Python 3.8.6 (64-bit)</li><li>Visual Studio Code</li></ul><h3 id=安装依赖>安装依赖:<a hidden class=anchor aria-hidden=true href=#安装依赖>#</a></h3><ul><li>selenium</li><li>openpyxl</li><li>bs4</li><li>pyyaml</li><li>tqdm</li><li>lxml</li></ul><h3 id=实现原理>实现原理:<a hidden class=anchor aria-hidden=true href=#实现原理>#</a></h3><ol><li>通过 <code>selenium</code> 调用 <code>chromedriver</code> 打开 chrome, 打开信息系统登录页面并模拟登录</li><li>登录成功后请求对应延误行李, 值班日志等页面, 使用 <code>BeautifulSoup</code>, <code>re</code> 爬取数据</li><li>对数据进行处理后, 使用 <code>openpyxl</code> 将数据写入 Excel 中</li><li>功能调试完成后将 chrome 设置为 headless browser, 优化使用体验</li></ol><h2 id=使用方法>使用方法<a hidden class=anchor aria-hidden=true href=#使用方法>#</a></h2><ol><li>打开 <code>config.yaml</code>, 按照指引修改 <code>账号</code>, <code>密码</code>, <code>起始日期</code>, <code>结束日期</code>, <code>刷新间隔</code>, <code>航站楼</code>, <code>内外网访问模式</code>, <code>运行模式</code>, 其中 <code>刷新间隔</code> 可按需修改, 修改完保存配置</li><li>运行 <code>main.exe</code> 或 <code>main.py</code></li><li>程序窗口将显示爬取进度, 运行完毕后, <code>统计结果</code> 以及 <code>分队排班表</code> 以 Excel 格式保存在 <code>\output</code> 目录中</li></ol><h2 id=后续>后续<a hidden class=anchor aria-hidden=true href=#后续>#</a></h2><p>脚本我从 <code>v1.0</code> 开始记录, 在使用过程中一直有遇到新的bug, 导致统计数字有问题, 期间也是一直有维护, 修了几个bug, 直到最近更新到了 <code>v2.6.3</code>, 相信统计功能已经接近完美 (flag)</p><p>不过也是多亏了同事一直有帮忙检验表格准确性, 这些 bug 才得以被修复, 如果是我自己用估计也不会发现.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://cgcel.github.io/tags/python/>python</a></li><li><a href=https://cgcel.github.io/tags/selenium/>selenium</a></li><li><a href=https://cgcel.github.io/tags/requests/>requests</a></li></ul><nav class=paginav><a class=prev href=https://cgcel.github.io/posts/2020/07/18/%E7%88%AC%E5%8F%96%E6%B4%AA%E7%81%BE%E6%9C%9F%E9%97%B4%E9%95%BF%E6%B1%9F%E6%B2%BF%E5%B2%B8%E6%B0%B4%E4%BD%8D%E5%B9%B6%E7%BB%98%E5%9B%BE/><span class=title>« Prev</span><br><span>爬取洪灾期间长江沿岸水位并绘图</span></a>
<a class=next href=https://cgcel.github.io/posts/2020/06/03/stm32%E7%9A%84%E4%B8%B2%E5%8F%A3%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/><span class=title>Next »</span><br><span>STM32的串口学习总结</span></a></nav></footer><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//https-cgcel-github-io.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></article></main><footer class=footer><span>&copy; 2022 <a href=https://cgcel.github.io>烂杯的博客</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerHTML="copy";function s(){e.innerHTML="copied!",setTimeout(()=>{e.innerHTML="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>